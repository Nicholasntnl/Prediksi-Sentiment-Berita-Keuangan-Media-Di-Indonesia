{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0447c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertTokenizer, BertModel, AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For tqdm progress bars\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e782c1ff",
   "metadata": {},
   "source": [
    "## Load CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca67a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnews = pd.read_csv('https://raw.githubusercontent.com/jasminemutia/dataset/main/media_news.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79ef235",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d108d9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7949 entries, 0 to 7948\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   URL     7949 non-null   object\n",
      " 1   Title   7949 non-null   object\n",
      " 2   Media   7949 non-null   object\n",
      " 3   Text    7927 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 248.5+ KB\n"
     ]
    }
   ],
   "source": [
    "dfnews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aa15c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah baris dalam data IBM:  7949\n",
      "Jumlah kolom dalam data IBM:  4\n"
     ]
    }
   ],
   "source": [
    "row, col = dfnews.shape\n",
    "print(\"Jumlah baris dalam data IBM: \", row)\n",
    "print(\"Jumlah kolom dalam data IBM: \", col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0c7f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnews = dfnews.drop([\"URL\", \"Media\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7b9435d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Menakar Dampak Resesi Jepang ke Pasar Modal In...</td>\n",
       "      <td>Liputan6.com, Jakarta Jepang mengalami technic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IHSG Lanjutkan Kenaikan, Investor Asing Borong...</td>\n",
       "      <td>Liputan6.com, Jakarta - Laju Indeks Harga Saha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suspensi Capai 4 Tahun, Bursa Ingatkan Potensi...</td>\n",
       "      <td>Liputan6.com, Jakarta Bursa Efek Indonesia (BE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lolos PKPU, Bursa Cabut Notasi Khusus M pada A...</td>\n",
       "      <td>Liputan6.com, Jakarta - Bursa Efek Indonesia (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bergerak Volatil, Bursa Cecar Emiten Panca Mit...</td>\n",
       "      <td>Liputan6.com, Jakarta Emiten pengolahan udang,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Menakar Dampak Resesi Jepang ke Pasar Modal In...   \n",
       "1  IHSG Lanjutkan Kenaikan, Investor Asing Borong...   \n",
       "2  Suspensi Capai 4 Tahun, Bursa Ingatkan Potensi...   \n",
       "3  Lolos PKPU, Bursa Cabut Notasi Khusus M pada A...   \n",
       "4  Bergerak Volatil, Bursa Cecar Emiten Panca Mit...   \n",
       "\n",
       "                                                Text  \n",
       "0  Liputan6.com, Jakarta Jepang mengalami technic...  \n",
       "1  Liputan6.com, Jakarta - Laju Indeks Harga Saha...  \n",
       "2  Liputan6.com, Jakarta Bursa Efek Indonesia (BE...  \n",
       "3  Liputan6.com, Jakarta - Bursa Efek Indonesia (...  \n",
       "4  Liputan6.com, Jakarta Emiten pengolahan udang,...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0f2dbf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnews.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f223d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Menakar Dampak Resesi Jepang ke Pasar Modal In...</td>\n",
       "      <td>Liputan6.com, Jakarta Jepang mengalami technic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IHSG Lanjutkan Kenaikan, Investor Asing Borong...</td>\n",
       "      <td>Liputan6.com, Jakarta - Laju Indeks Harga Saha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suspensi Capai 4 Tahun, Bursa Ingatkan Potensi...</td>\n",
       "      <td>Liputan6.com, Jakarta Bursa Efek Indonesia (BE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lolos PKPU, Bursa Cabut Notasi Khusus M pada A...</td>\n",
       "      <td>Liputan6.com, Jakarta - Bursa Efek Indonesia (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bergerak Volatil, Bursa Cecar Emiten Panca Mit...</td>\n",
       "      <td>Liputan6.com, Jakarta Emiten pengolahan udang,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7544</th>\n",
       "      <td>Saham China dibuka lebih rendah, indeks Shangh...</td>\n",
       "      <td>Saham China dibuka lebih rendah, indeks Shangh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7545</th>\n",
       "      <td>Emas jatuh di bawah level kunci 2.000 dolar ka...</td>\n",
       "      <td>Emas jatuh di bawah level kunci 2.000 dolar ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7546</th>\n",
       "      <td>Saham Inggris berakhir negatif, indeks FTSE 10...</td>\n",
       "      <td>Saham Inggris berakhir negatif, indeks FTSE 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7547</th>\n",
       "      <td>Saham Jerman berbalik melemah, indeks DAX 40 t...</td>\n",
       "      <td>Saham Jerman berbalik melemah, indeks DAX 40 t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7548</th>\n",
       "      <td>Saham Prancis hentikan reli 3-hari, indeks CAC...</td>\n",
       "      <td>Saham Prancis hentikan reli 3-hari, indeks CAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7546 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  \\\n",
       "0     Menakar Dampak Resesi Jepang ke Pasar Modal In...   \n",
       "1     IHSG Lanjutkan Kenaikan, Investor Asing Borong...   \n",
       "2     Suspensi Capai 4 Tahun, Bursa Ingatkan Potensi...   \n",
       "3     Lolos PKPU, Bursa Cabut Notasi Khusus M pada A...   \n",
       "4     Bergerak Volatil, Bursa Cecar Emiten Panca Mit...   \n",
       "...                                                 ...   \n",
       "7544  Saham China dibuka lebih rendah, indeks Shangh...   \n",
       "7545  Emas jatuh di bawah level kunci 2.000 dolar ka...   \n",
       "7546  Saham Inggris berakhir negatif, indeks FTSE 10...   \n",
       "7547  Saham Jerman berbalik melemah, indeks DAX 40 t...   \n",
       "7548  Saham Prancis hentikan reli 3-hari, indeks CAC...   \n",
       "\n",
       "                                                   Text  \n",
       "0     Liputan6.com, Jakarta Jepang mengalami technic...  \n",
       "1     Liputan6.com, Jakarta - Laju Indeks Harga Saha...  \n",
       "2     Liputan6.com, Jakarta Bursa Efek Indonesia (BE...  \n",
       "3     Liputan6.com, Jakarta - Bursa Efek Indonesia (...  \n",
       "4     Liputan6.com, Jakarta Emiten pengolahan udang,...  \n",
       "...                                                 ...  \n",
       "7544  Saham China dibuka lebih rendah, indeks Shangh...  \n",
       "7545  Emas jatuh di bawah level kunci 2.000 dolar ka...  \n",
       "7546  Saham Inggris berakhir negatif, indeks FTSE 10...  \n",
       "7547  Saham Jerman berbalik melemah, indeks DAX 40 t...  \n",
       "7548  Saham Prancis hentikan reli 3-hari, indeks CAC...  \n",
       "\n",
       "[7546 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnews = dfnews.drop_duplicates()\n",
    "dfnews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df9b047a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnews['Text'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cdf149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnews = dfnews.dropna(subset=['Text']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0fd672d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7524, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e6b0704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Menakar Dampak Resesi Jepang ke Pasar Modal In...</td>\n",
       "      <td>Liputan6.com, Jakarta Jepang mengalami technic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IHSG Lanjutkan Kenaikan, Investor Asing Borong...</td>\n",
       "      <td>Liputan6.com, Jakarta - Laju Indeks Harga Saha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suspensi Capai 4 Tahun, Bursa Ingatkan Potensi...</td>\n",
       "      <td>Liputan6.com, Jakarta Bursa Efek Indonesia (BE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lolos PKPU, Bursa Cabut Notasi Khusus M pada A...</td>\n",
       "      <td>Liputan6.com, Jakarta - Bursa Efek Indonesia (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bergerak Volatil, Bursa Cecar Emiten Panca Mit...</td>\n",
       "      <td>Liputan6.com, Jakarta Emiten pengolahan udang,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>Saham China dibuka lebih rendah, indeks Shangh...</td>\n",
       "      <td>Saham China dibuka lebih rendah, indeks Shangh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>Emas jatuh di bawah level kunci 2.000 dolar ka...</td>\n",
       "      <td>Emas jatuh di bawah level kunci 2.000 dolar ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7521</th>\n",
       "      <td>Saham Inggris berakhir negatif, indeks FTSE 10...</td>\n",
       "      <td>Saham Inggris berakhir negatif, indeks FTSE 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7522</th>\n",
       "      <td>Saham Jerman berbalik melemah, indeks DAX 40 t...</td>\n",
       "      <td>Saham Jerman berbalik melemah, indeks DAX 40 t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7523</th>\n",
       "      <td>Saham Prancis hentikan reli 3-hari, indeks CAC...</td>\n",
       "      <td>Saham Prancis hentikan reli 3-hari, indeks CAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7524 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  \\\n",
       "0     Menakar Dampak Resesi Jepang ke Pasar Modal In...   \n",
       "1     IHSG Lanjutkan Kenaikan, Investor Asing Borong...   \n",
       "2     Suspensi Capai 4 Tahun, Bursa Ingatkan Potensi...   \n",
       "3     Lolos PKPU, Bursa Cabut Notasi Khusus M pada A...   \n",
       "4     Bergerak Volatil, Bursa Cecar Emiten Panca Mit...   \n",
       "...                                                 ...   \n",
       "7519  Saham China dibuka lebih rendah, indeks Shangh...   \n",
       "7520  Emas jatuh di bawah level kunci 2.000 dolar ka...   \n",
       "7521  Saham Inggris berakhir negatif, indeks FTSE 10...   \n",
       "7522  Saham Jerman berbalik melemah, indeks DAX 40 t...   \n",
       "7523  Saham Prancis hentikan reli 3-hari, indeks CAC...   \n",
       "\n",
       "                                                   Text  \n",
       "0     Liputan6.com, Jakarta Jepang mengalami technic...  \n",
       "1     Liputan6.com, Jakarta - Laju Indeks Harga Saha...  \n",
       "2     Liputan6.com, Jakarta Bursa Efek Indonesia (BE...  \n",
       "3     Liputan6.com, Jakarta - Bursa Efek Indonesia (...  \n",
       "4     Liputan6.com, Jakarta Emiten pengolahan udang,...  \n",
       "...                                                 ...  \n",
       "7519  Saham China dibuka lebih rendah, indeks Shangh...  \n",
       "7520  Emas jatuh di bawah level kunci 2.000 dolar ka...  \n",
       "7521  Saham Inggris berakhir negatif, indeks FTSE 10...  \n",
       "7522  Saham Jerman berbalik melemah, indeks DAX 40 t...  \n",
       "7523  Saham Prancis hentikan reli 3-hari, indeks CAC...  \n",
       "\n",
       "[7524 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd80d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnews.to_csv(\"media_news_unlabelled.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c05c75e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnews_unlabelled = pd.read_csv('https://raw.githubusercontent.com/jasminemutia/dataset/main/media_news_unlabelled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f1d256",
   "metadata": {},
   "source": [
    "## Labelling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5000ad82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labelled = pd.read_csv('https://raw.githubusercontent.com/jasminemutia/dataset/main/media_news_labelled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cf811b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapus baris yang memiliki label \"Null\"\n",
    "df_labelled = df_labelled[df_labelled['Sentiment'] != 'Null']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "224cc1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Menakar Dampak Resesi Jepang ke Pasar Modal In...</td>\n",
       "      <td>Liputan6.com, Jakarta Jepang mengalami technic...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IHSG Lanjutkan Kenaikan, Investor Asing Borong...</td>\n",
       "      <td>Liputan6.com, Jakarta - Laju Indeks Harga Saha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suspensi Capai 4 Tahun, Bursa Ingatkan Potensi...</td>\n",
       "      <td>Liputan6.com, Jakarta Bursa Efek Indonesia (BE...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bergerak Volatil, Bursa Cecar Emiten Panca Mit...</td>\n",
       "      <td>Liputan6.com, Jakarta Emiten pengolahan udang,...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stock Split 1:2, Tembaga Mulia Semanan Umumkan...</td>\n",
       "      <td>Liputan6.com, Jakarta PT Tembaga Mulia Semanan...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7519</th>\n",
       "      <td>Saham China dibuka lebih rendah, indeks Shangh...</td>\n",
       "      <td>Saham China dibuka lebih rendah, indeks Shangh...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7520</th>\n",
       "      <td>Emas jatuh di bawah level kunci 2.000 dolar ka...</td>\n",
       "      <td>Emas jatuh di bawah level kunci 2.000 dolar ka...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7521</th>\n",
       "      <td>Saham Inggris berakhir negatif, indeks FTSE 10...</td>\n",
       "      <td>Saham Inggris berakhir negatif, indeks FTSE 10...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7522</th>\n",
       "      <td>Saham Jerman berbalik melemah, indeks DAX 40 t...</td>\n",
       "      <td>Saham Jerman berbalik melemah, indeks DAX 40 t...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7523</th>\n",
       "      <td>Saham Prancis hentikan reli 3-hari, indeks CAC...</td>\n",
       "      <td>Saham Prancis hentikan reli 3-hari, indeks CAC...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7328 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  \\\n",
       "0     Menakar Dampak Resesi Jepang ke Pasar Modal In...   \n",
       "1     IHSG Lanjutkan Kenaikan, Investor Asing Borong...   \n",
       "2     Suspensi Capai 4 Tahun, Bursa Ingatkan Potensi...   \n",
       "4     Bergerak Volatil, Bursa Cecar Emiten Panca Mit...   \n",
       "6     Stock Split 1:2, Tembaga Mulia Semanan Umumkan...   \n",
       "...                                                 ...   \n",
       "7519  Saham China dibuka lebih rendah, indeks Shangh...   \n",
       "7520  Emas jatuh di bawah level kunci 2.000 dolar ka...   \n",
       "7521  Saham Inggris berakhir negatif, indeks FTSE 10...   \n",
       "7522  Saham Jerman berbalik melemah, indeks DAX 40 t...   \n",
       "7523  Saham Prancis hentikan reli 3-hari, indeks CAC...   \n",
       "\n",
       "                                                   Text Sentiment  \n",
       "0     Liputan6.com, Jakarta Jepang mengalami technic...  Positive  \n",
       "1     Liputan6.com, Jakarta - Laju Indeks Harga Saha...  Positive  \n",
       "2     Liputan6.com, Jakarta Bursa Efek Indonesia (BE...   Neutral  \n",
       "4     Liputan6.com, Jakarta Emiten pengolahan udang,...   Neutral  \n",
       "6     Liputan6.com, Jakarta PT Tembaga Mulia Semanan...  Positive  \n",
       "...                                                 ...       ...  \n",
       "7519  Saham China dibuka lebih rendah, indeks Shangh...  Negative  \n",
       "7520  Emas jatuh di bawah level kunci 2.000 dolar ka...  Negative  \n",
       "7521  Saham Inggris berakhir negatif, indeks FTSE 10...  Negative  \n",
       "7522  Saham Jerman berbalik melemah, indeks DAX 40 t...  Negative  \n",
       "7523  Saham Prancis hentikan reli 3-hari, indeks CAC...  Negative  \n",
       "\n",
       "[7328 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70711086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labelled.to_csv(\"news_sentiment.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300a2a0c",
   "metadata": {},
   "source": [
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e521464",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labelled = pd.read_csv(\"https://raw.githubusercontent.com/jasminemutia/dataset/main/news_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "973e9c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Menakar Dampak Resesi Jepang ke Pasar Modal In...</td>\n",
       "      <td>Liputan6.com, Jakarta Jepang mengalami technic...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IHSG Lanjutkan Kenaikan, Investor Asing Borong...</td>\n",
       "      <td>Liputan6.com, Jakarta - Laju Indeks Harga Saha...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suspensi Capai 4 Tahun, Bursa Ingatkan Potensi...</td>\n",
       "      <td>Liputan6.com, Jakarta Bursa Efek Indonesia (BE...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bergerak Volatil, Bursa Cecar Emiten Panca Mit...</td>\n",
       "      <td>Liputan6.com, Jakarta Emiten pengolahan udang,...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stock Split 1:2, Tembaga Mulia Semanan Umumkan...</td>\n",
       "      <td>Liputan6.com, Jakarta PT Tembaga Mulia Semanan...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7323</th>\n",
       "      <td>Saham China dibuka lebih rendah, indeks Shangh...</td>\n",
       "      <td>Saham China dibuka lebih rendah, indeks Shangh...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7324</th>\n",
       "      <td>Emas jatuh di bawah level kunci 2.000 dolar ka...</td>\n",
       "      <td>Emas jatuh di bawah level kunci 2.000 dolar ka...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7325</th>\n",
       "      <td>Saham Inggris berakhir negatif, indeks FTSE 10...</td>\n",
       "      <td>Saham Inggris berakhir negatif, indeks FTSE 10...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7326</th>\n",
       "      <td>Saham Jerman berbalik melemah, indeks DAX 40 t...</td>\n",
       "      <td>Saham Jerman berbalik melemah, indeks DAX 40 t...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7327</th>\n",
       "      <td>Saham Prancis hentikan reli 3-hari, indeks CAC...</td>\n",
       "      <td>Saham Prancis hentikan reli 3-hari, indeks CAC...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7328 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  \\\n",
       "0     Menakar Dampak Resesi Jepang ke Pasar Modal In...   \n",
       "1     IHSG Lanjutkan Kenaikan, Investor Asing Borong...   \n",
       "2     Suspensi Capai 4 Tahun, Bursa Ingatkan Potensi...   \n",
       "3     Bergerak Volatil, Bursa Cecar Emiten Panca Mit...   \n",
       "4     Stock Split 1:2, Tembaga Mulia Semanan Umumkan...   \n",
       "...                                                 ...   \n",
       "7323  Saham China dibuka lebih rendah, indeks Shangh...   \n",
       "7324  Emas jatuh di bawah level kunci 2.000 dolar ka...   \n",
       "7325  Saham Inggris berakhir negatif, indeks FTSE 10...   \n",
       "7326  Saham Jerman berbalik melemah, indeks DAX 40 t...   \n",
       "7327  Saham Prancis hentikan reli 3-hari, indeks CAC...   \n",
       "\n",
       "                                                   Text Sentiment  \n",
       "0     Liputan6.com, Jakarta Jepang mengalami technic...  Positive  \n",
       "1     Liputan6.com, Jakarta - Laju Indeks Harga Saha...  Positive  \n",
       "2     Liputan6.com, Jakarta Bursa Efek Indonesia (BE...   Neutral  \n",
       "3     Liputan6.com, Jakarta Emiten pengolahan udang,...   Neutral  \n",
       "4     Liputan6.com, Jakarta PT Tembaga Mulia Semanan...  Positive  \n",
       "...                                                 ...       ...  \n",
       "7323  Saham China dibuka lebih rendah, indeks Shangh...  Negative  \n",
       "7324  Emas jatuh di bawah level kunci 2.000 dolar ka...  Negative  \n",
       "7325  Saham Inggris berakhir negatif, indeks FTSE 10...  Negative  \n",
       "7326  Saham Jerman berbalik melemah, indeks DAX 40 t...  Negative  \n",
       "7327  Saham Prancis hentikan reli 3-hari, indeks CAC...  Negative  \n",
       "\n",
       "[7328 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8f97cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String punctuation to be removed:  !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(\"String punctuation to be removed: \", string.punctuation)\n",
    "\n",
    "# Buat kolom baru untuk menyimpan teks yang sudah dibersihkan\n",
    "df_labelled['Clean Text'] = df_labelled['Text'].copy()\n",
    "df_labelled['Clean Text'] = df_labelled['Clean Text'].str.lower()\n",
    "# Remove Number\n",
    "df_labelled['Clean Text'] = df_labelled['Clean Text'].str.replace(r'\\d+', '', regex=True)\n",
    "# Remove \"https\" and \".com\"\n",
    "df_labelled['Clean Text'] = df_labelled['Clean Text'].str.replace(r'\\.com|\\.id|\\.co', '',regex=True)\n",
    "df_labelled['Clean Text'] = df_labelled['Clean Text'].str.replace(r'https\\S+|http\\S+|www\\.\\S+','', regex=True)\n",
    "# Remove Enter\n",
    "df_labelled['Clean Text'] = df_labelled['Clean Text'].str.replace(r'\\n', ' ', regex=True)\n",
    "# Remove punctuation from the 'text' column\n",
    "df_labelled['Clean Text'] = df_labelled['Clean Text'].str.replace('[{}]'.format(string.punctuation), '', regex=True)\n",
    "\n",
    "# Additional symbol removal\n",
    "additional_symbols = r'[Â©Ã¢â‚¬â€œÅ“]'\n",
    "df_labelled['Clean Text'] = df_labelled['Clean Text'].str.replace(additional_symbols, '', regex=True)\n",
    "\n",
    "# # remove stop words\n",
    "# stop = set(stopwords.words('indonesian'))\n",
    "# text = [x for x in df_labelled['Text'] if x not in stop]\n",
    "\n",
    "# Remove multiple whitespcae\n",
    "def remove_whitespace(text):\n",
    "  if isinstance(text, str):\n",
    "    return re.sub(r'\\s+', ' ', text)\n",
    "  else:\n",
    "    return text\n",
    "\n",
    "df_labelled['Clean Text'] = df_labelled['Clean Text'].apply(remove_whitespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26f419b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nicho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d49ea01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengambil stopwords bahasa Indonesia\n",
    "stop = set(stopwords.words('indonesian'))\n",
    "\n",
    "# Fungsi untuk menghapus stopwords dari teks\n",
    "def remove_stopwords(text):\n",
    "    if isinstance(text, str):\n",
    "        # Membagi teks menjadi kata-kata\n",
    "        words = text.split()\n",
    "        # Menghapus stopwords\n",
    "        filtered_words = [word for word in words if word.lower() not in stop]\n",
    "        # Menggabungkan kata-kata kembali menjadi teks\n",
    "        return ' '.join(filtered_words)\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Terapkan fungsi remove_stopwords pada kolom 'Text'\n",
    "df_labelled['Clean Text'] = df_labelled['Clean Text'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d291d484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Clean Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Menakar Dampak Resesi Jepang ke Pasar Modal In...</td>\n",
       "      <td>Liputan6.com, Jakarta Jepang mengalami technic...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>liputan jakarta jepang mengalami technical rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IHSG Lanjutkan Kenaikan, Investor Asing Borong...</td>\n",
       "      <td>Liputan6.com, Jakarta - Laju Indeks Harga Saha...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>liputan jakarta laju indeks harga saham gabung...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Suspensi Capai 4 Tahun, Bursa Ingatkan Potensi...</td>\n",
       "      <td>Liputan6.com, Jakarta Bursa Efek Indonesia (BE...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>liputan jakarta bursa efek indonesia bei mengu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bergerak Volatil, Bursa Cecar Emiten Panca Mit...</td>\n",
       "      <td>Liputan6.com, Jakarta Emiten pengolahan udang,...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>liputan jakarta emiten pengolahan udang pt pan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stock Split 1:2, Tembaga Mulia Semanan Umumkan...</td>\n",
       "      <td>Liputan6.com, Jakarta PT Tembaga Mulia Semanan...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>liputan jakarta pt tembaga mulia semanan tbk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7323</th>\n",
       "      <td>Saham China dibuka lebih rendah, indeks Shangh...</td>\n",
       "      <td>Saham China dibuka lebih rendah, indeks Shangh...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>saham china dibuka rendah indeks shanghai jatu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7324</th>\n",
       "      <td>Emas jatuh di bawah level kunci 2.000 dolar ka...</td>\n",
       "      <td>Emas jatuh di bawah level kunci 2.000 dolar ka...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>emas jatuh level kunci dolar greenback menguat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7325</th>\n",
       "      <td>Saham Inggris berakhir negatif, indeks FTSE 10...</td>\n",
       "      <td>Saham Inggris berakhir negatif, indeks FTSE 10...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>saham inggris negatif indeks ftse berkurang pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7326</th>\n",
       "      <td>Saham Jerman berbalik melemah, indeks DAX 40 t...</td>\n",
       "      <td>Saham Jerman berbalik melemah, indeks DAX 40 t...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>saham jerman berbalik melemah indeks dax terpa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7327</th>\n",
       "      <td>Saham Prancis hentikan reli 3-hari, indeks CAC...</td>\n",
       "      <td>Saham Prancis hentikan reli 3-hari, indeks CAC...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>saham prancis hentikan reli indeks cac merosot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7328 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  \\\n",
       "0     Menakar Dampak Resesi Jepang ke Pasar Modal In...   \n",
       "1     IHSG Lanjutkan Kenaikan, Investor Asing Borong...   \n",
       "2     Suspensi Capai 4 Tahun, Bursa Ingatkan Potensi...   \n",
       "3     Bergerak Volatil, Bursa Cecar Emiten Panca Mit...   \n",
       "4     Stock Split 1:2, Tembaga Mulia Semanan Umumkan...   \n",
       "...                                                 ...   \n",
       "7323  Saham China dibuka lebih rendah, indeks Shangh...   \n",
       "7324  Emas jatuh di bawah level kunci 2.000 dolar ka...   \n",
       "7325  Saham Inggris berakhir negatif, indeks FTSE 10...   \n",
       "7326  Saham Jerman berbalik melemah, indeks DAX 40 t...   \n",
       "7327  Saham Prancis hentikan reli 3-hari, indeks CAC...   \n",
       "\n",
       "                                                   Text Sentiment  \\\n",
       "0     Liputan6.com, Jakarta Jepang mengalami technic...  Positive   \n",
       "1     Liputan6.com, Jakarta - Laju Indeks Harga Saha...  Positive   \n",
       "2     Liputan6.com, Jakarta Bursa Efek Indonesia (BE...   Neutral   \n",
       "3     Liputan6.com, Jakarta Emiten pengolahan udang,...   Neutral   \n",
       "4     Liputan6.com, Jakarta PT Tembaga Mulia Semanan...  Positive   \n",
       "...                                                 ...       ...   \n",
       "7323  Saham China dibuka lebih rendah, indeks Shangh...  Negative   \n",
       "7324  Emas jatuh di bawah level kunci 2.000 dolar ka...  Negative   \n",
       "7325  Saham Inggris berakhir negatif, indeks FTSE 10...  Negative   \n",
       "7326  Saham Jerman berbalik melemah, indeks DAX 40 t...  Negative   \n",
       "7327  Saham Prancis hentikan reli 3-hari, indeks CAC...  Negative   \n",
       "\n",
       "                                             Clean Text  \n",
       "0     liputan jakarta jepang mengalami technical rec...  \n",
       "1     liputan jakarta laju indeks harga saham gabung...  \n",
       "2     liputan jakarta bursa efek indonesia bei mengu...  \n",
       "3     liputan jakarta emiten pengolahan udang pt pan...  \n",
       "4     liputan jakarta pt tembaga mulia semanan tbk t...  \n",
       "...                                                 ...  \n",
       "7323  saham china dibuka rendah indeks shanghai jatu...  \n",
       "7324  emas jatuh level kunci dolar greenback menguat...  \n",
       "7325  saham inggris negatif indeks ftse berkurang pe...  \n",
       "7326  saham jerman berbalik melemah indeks dax terpa...  \n",
       "7327  saham prancis hentikan reli indeks cac merosot...  \n",
       "\n",
       "[7328 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labelled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46c681c",
   "metadata": {},
   "source": [
    "## Data Splitting LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6220b7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah data pada training set : 5862\n",
      "Jumlah data pada validation set : 733\n",
      "Jumlah data pada testing set : 733\n"
     ]
    }
   ],
   "source": [
    "# Splitting the summarized data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(df_labelled['Clean Text'], df_labelled['Sentiment'], test_size=0.2, random_state=32, stratify=df_labelled['Sentiment'])\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=32, stratify=y_temp)\n",
    "\n",
    "print(\"Jumlah data pada training set :\", len(X_train))\n",
    "print(\"Jumlah data pada validation set :\", len(X_val))\n",
    "print(\"Jumlah data pada testing set :\", len(X_test))\n",
    "\n",
    "# Recreate DataFrames for each split\n",
    "df_train = pd.DataFrame({\n",
    "    'Clean Text': X_train,\n",
    "    'Sentiment': y_train\n",
    "})\n",
    "\n",
    "df_val = pd.DataFrame({\n",
    "    'Clean Text': X_val,\n",
    "    'Sentiment': y_val\n",
    "})\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    'Clean Text': X_test,\n",
    "    'Sentiment': y_test\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dea000",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33cd0bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nicho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "234cd50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5307    [idxchannel, bursa, efek, indonesia, bei, peri...\n",
      "5900    [koci, raup, rp, miliar, dana, ipo, mayoritas,...\n",
      "1809    [nilai, tukar, rupiah, posisi, rp, dolar, as, ...\n",
      "1239    [jakarta, kompas, pemilik, waralaba, kebab, tu...\n",
      "2722    [presiden, joko, widodo, jokowi, resmi, mewaji...\n",
      "Name: Clean Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    " #Fungsi untuk tokenisasi teks\n",
    "def tokenize_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Tokenisasi kata\n",
    "        word_tokens = word_tokenize(text)\n",
    "        return word_tokens\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Terapkan fungsi tokenize_text pada kolom teks yang akan ditokenisasi\n",
    "X_train = X_train.apply(tokenize_text)\n",
    "\n",
    "# Tampilkan hasil tokenisasi\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fceb8239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566     [jakarta, kompas, kehadiran, papan, pemantauan...\n",
      "376     [jakarta, kompas, indeks, harga, saham, gabung...\n",
      "7152    [saham, china, dibuka, rendah, indeks, shangha...\n",
      "4554    [jakarta, cnbc, indonesia, cio, mandiri, manaj...\n",
      "5598    [ihsg, ditutup, menguat, pasar, respon, sikap,...\n",
      "Name: Clean Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    " #Fungsi untuk tokenisasi teks\n",
    "def tokenize_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Tokenisasi kata\n",
    "        word_tokens = word_tokenize(text)\n",
    "        return word_tokens\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Terapkan fungsi tokenize_text pada kolom teks yang akan ditokenisasi\n",
    "X_test = X_test.apply(tokenize_text)\n",
    "\n",
    "# Tampilkan hasil tokenisasi\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19148602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7300    [saham, inggris, berbalik, menguat, indeks, ft...\n",
      "2006    [menteri, bumn, erick, thohir, menyebut, harga...\n",
      "6797    [ihsg, pekan, ditutup, melemah, ikuti, bursa, ...\n",
      "578     [kompas, chief, executive, officer, ceo, cofou...\n",
      "6670    [metrodata, electronics, raih, pendapatan, rp,...\n",
      "Name: Clean Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    " #Fungsi untuk tokenisasi teks\n",
    "def tokenize_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Tokenisasi kata\n",
    "        word_tokens = word_tokenize(text)\n",
    "        return word_tokens\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Terapkan fungsi tokenize_text pada kolom teks yang akan ditokenisasi\n",
    "X_val = X_val.apply(tokenize_text)\n",
    "\n",
    "# Tampilkan hasil tokenisasi\n",
    "print(X_val.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a880aca8",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2c83646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nicho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nicho\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download the required NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "936ce69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5307    [idxchannel, bursa, efek, indonesia, bei, peri...\n",
      "5900    [koci, raup, rp, miliar, dana, ipo, mayoritas,...\n",
      "1809    [nilai, tukar, rupiah, posisi, rp, dolar, a, d...\n",
      "1239    [jakarta, kompas, pemilik, waralaba, kebab, tu...\n",
      "2722    [presiden, joko, widodo, jokowi, resmi, mewaji...\n",
      "Name: Clean Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Fungsi untuk lemmatisasi teks\n",
    "def lemmatize_text(text):\n",
    "    if isinstance(text, list):\n",
    "        # Lemmatisasi kata\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(token) for token in text]\n",
    "        return lemmatized_tokens\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Terapkan fungsi lemmatize_text pada kolom 'Text'\n",
    "X_train = X_train.apply(lemmatize_text)\n",
    "\n",
    "# Tampilkan hasil lemmatisasi\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1abd1f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566     [jakarta, kompas, kehadiran, papan, pemantauan...\n",
      "376     [jakarta, kompas, indeks, harga, saham, gabung...\n",
      "7152    [saham, china, dibuka, rendah, indeks, shangha...\n",
      "4554    [jakarta, cnbc, indonesia, cio, mandiri, manaj...\n",
      "5598    [ihsg, ditutup, menguat, pasar, respon, sikap,...\n",
      "Name: Clean Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Fungsi untuk lemmatisasi teks\n",
    "def lemmatize_text(text):\n",
    "    if isinstance(text, list):\n",
    "        # Lemmatisasi kata\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(token) for token in text]\n",
    "        return lemmatized_tokens\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Terapkan fungsi lemmatize_text pada kolom 'Text'\n",
    "X_test = X_test.apply(lemmatize_text)\n",
    "\n",
    "# Tampilkan hasil lemmatisasi\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94029928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7300    [saham, inggris, berbalik, menguat, indeks, ft...\n",
      "2006    [menteri, bumn, erick, thohir, menyebut, harga...\n",
      "6797    [ihsg, pekan, ditutup, melemah, ikuti, bursa, ...\n",
      "578     [kompas, chief, executive, officer, ceo, cofou...\n",
      "6670    [metrodata, electronics, raih, pendapatan, rp,...\n",
      "Name: Clean Text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Fungsi untuk lemmatisasi teks\n",
    "def lemmatize_text(text):\n",
    "    if isinstance(text, list):\n",
    "        # Lemmatisasi kata\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(token) for token in text]\n",
    "        return lemmatized_tokens\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Terapkan fungsi lemmatize_text pada kolom 'Text'\n",
    "X_val = X_val.apply(lemmatize_text)\n",
    "\n",
    "# Tampilkan hasil lemmatisasi\n",
    "print(X_val.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85af6f7",
   "metadata": {},
   "source": [
    "## Vectorization Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31c58474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class for BERT\n",
    "class FinancialNewsDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_len):\n",
    "        #self.texts = df_labelled['Clean Text'].tolist()\n",
    "        self.texts = df['Clean Text'].tolist()  # Menggunakan df yang benar\n",
    "        self.labels = df['Sentiment'].apply(\n",
    "            lambda x: 0 if x == 'Negative' else\n",
    "                      1 if x == 'Neutral' else\n",
    "                      2 if x == 'Positive' else\n",
    "                      3 if x == 'Dual' else None  # Hindari -1\n",
    "        ).dropna().tolist()  # Hapus data dengan label None\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a3af005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('indolem/indobert-base-uncased')\n",
    "\n",
    "# Define max length for tokenized inputs\n",
    "MAX_LEN = 128\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = FinancialNewsDataset(df_train, tokenizer, MAX_LEN)\n",
    "val_dataset = FinancialNewsDataset(df_val, tokenizer, MAX_LEN)\n",
    "test_dataset = FinancialNewsDataset(df_test, tokenizer, MAX_LEN)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5e8291",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91e4b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifierTune(nn.Module):\n",
    "    def __init__(self, dropout=0.3):\n",
    "        super(BertClassifierTune, self).__init__()  # Corrected class name\n",
    "        self.bert = BertModel.from_pretrained('indolem/indobert-base-uncased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Add extra fully connected layer\n",
    "        self.fc1 = nn.Linear(768, 256)  # First hidden layer\n",
    "        self.relu = nn.ReLU()  # Activation function\n",
    "\n",
    "        # Final classifier layer for 4 classes\n",
    "        self.fc2 = nn.Linear(256, 4)  # 4 classes: Negative, Neutral, Positive, Dual\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n",
    "\n",
    "        # Pass through dropout\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "\n",
    "        # First fully connected layer + activation\n",
    "        fc1_output = self.fc1(dropout_output)\n",
    "        relu_output = self.relu(fc1_output)\n",
    "\n",
    "        # Final fully connected layer for classification\n",
    "        output = self.fc2(relu_output)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0733d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, val_dataloader, epochs, lr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss, total_train_acc = 0, 0\n",
    "\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            total_train_acc += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        val_loss, val_acc = evaluate(model, val_dataloader, criterion, device)\n",
    "        print(f'Epoch {epoch + 1}: Train Loss: {total_train_loss / len(train_dataloader):.3f}, Train Acc: {total_train_acc / len(df_train):.3f}, Val Loss: {val_loss:.3f}, Val Acc: {val_acc:.3f}')\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, total_acc = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Harus (batch_size, 4)\n",
    "            # Harus (batch_size,)\n",
    "            # print(f\"Output size: {outputs.size()}\", flush=True)  # Force print output immediately\n",
    "            # print(f\"Label size: {labels.size()}\", flush=True)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_acc += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "    return total_loss / len(dataloader), total_acc / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "048e830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tuning_v2(model, df_train, df_val, tokenizer, max_len, epochs, lr, batch_size):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    # Create DataLoaders with batch size specified during tuning\n",
    "    train_dataset = FinancialNewsDataset(df_train, tokenizer, max_len)\n",
    "    val_dataset = FinancialNewsDataset(df_val, tokenizer, max_len)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience, patience_counter = 2, 0  # Adjust patience as needed\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_train_loss, total_train_acc = 0, 0\n",
    "\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "            total_train_acc += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "\n",
    "        val_loss, val_acc = evaluate(model, val_dataloader, criterion, device)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "        print(f'Epoch {epoch + 1}: Train Loss: {total_train_loss / len(train_dataloader):.3f}, Train Acc: {total_train_acc / len(df_train):.3f}, Val Loss: {val_loss:.3f}, Val Acc: {val_acc:.3f}')\n",
    "\n",
    "# Evaluate function remains the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a06d3f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 184/184 [29:57<00:00,  9.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 1.073, Train Acc: 0.539, Val Loss: 0.926, Val Acc: 0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 184/184 [30:36<00:00,  9.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 0.850, Train Acc: 0.687, Val Loss: 0.819, Val Acc: 0.681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 184/184 [31:00<00:00, 10.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 0.741, Train Acc: 0.729, Val Loss: 0.792, Val Acc: 0.693\n"
     ]
    }
   ],
   "source": [
    "model2RelU = BertClassifierTune()\n",
    "EPOCHS = 3\n",
    "LR = 1e-5\n",
    "BATCH_SIZE = 32  # Ubah sesuai kebutuhan\n",
    "\n",
    "train_tuning_v2(model2RelU, df_train, df_val, tokenizer, MAX_LEN, epochs=EPOCHS, lr=LR, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8492d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.806, Test Accuracy: 0.690\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model2RelU, test_dataloader, nn.CrossEntropyLoss(), device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "print(f'Test Loss: {test_loss:.3f}, Test Accuracy: {test_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0cc030c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Menyimpan hanya state_dict model\n",
    "torch.save(model2RelU.state_dict(), 'bert_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6c96cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertClassifierTune(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31923, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc1): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=256, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Memuat state_dict model\n",
    "model2RelU.load_state_dict(torch.load('bert_model.pth'))\n",
    "\n",
    "# Pastikan model dalam mode evaluasi setelah memuat\n",
    "model2RelU.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "462255d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model2RelU.state_dict(), 'bert_model_state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd6f4676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.token_type_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('bert_model_state_dict.pt')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4d2d43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
